{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 7\n",
    "\n",
    "## Due Thursday, November 29th 2018 at 11:59 PM.\n",
    "\n",
    "### Be sure to push the final version of your notebook to your GitHub repo.  Follow the instructions on the course website.\n",
    "\n",
    "### Topics\n",
    "####  [Part 1](#part_1):  Database schema [15 points]\n",
    "* [Problem 1](#p1.1). Schema [15 points]\n",
    "\n",
    "####  [Part 2](#part_2):  Insert records [35 points]\n",
    "* [Problem 2](#p2.1). Baseline model [15 points]\n",
    "* [Problem 3](#p2.2). Reduced model [10 points]\n",
    "* [Problem 4](#p2.3). L1 penalty model [10 points]\n",
    "\n",
    "####  [Part 3](#part_3):  Queries [20 pts]\n",
    "* [Problem 5](#p3.1). Best model coefficients [10 points]\n",
    "* [Problem 6](#p3.2). Best model score [10 points]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part_1'></a>\n",
    "# Part 1:  Database schema\n",
    "\n",
    "<a id='p1.1'></a>\n",
    "## Problem 1 (15 points): \n",
    "\n",
    "In this problem you will set up a SQL database using the `sqllite` package in Python. The purpose of the database will be to store parameters and model results related to a simple *Logistic Regression* problem. Rather than keeping the results in `Numpy` arrays as we usually do, the idea here is to make use of a `SQL` database to materialize the results so that it can easily be accessed from disk at a later stage.\n",
    "\n",
    "The design of the database should be flexible enough so that the results from different model iterations can be stored in the database. It should also be able to deal with a different set of features by model iteration.\n",
    "\n",
    "A list of the tables to include in the database and the relevant fields in each table is shown below (tables are in bold):\n",
    "\n",
    "**model_params**: \n",
    "* id \n",
    "* desc \n",
    "* param_name\n",
    "* value\n",
    "\n",
    "**model_coeffs**\n",
    "* id \n",
    "* desc \n",
    "* feature_name\n",
    "* value\n",
    "\n",
    "**model_results**\n",
    "* id \n",
    "* desc \n",
    "* train_score\n",
    "* test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `SQL` database called `regression.sqlite` containing the three tables shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part_2'></a>\n",
    "# Part 2: Insert records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will populate the database you created in the previous question with some records for a number of different model iterations / scenarios.\n",
    "\n",
    "<a id='p2.1'></a>\n",
    "## Problem 2 (15 points): \n",
    "Create a baseline Logistic Regression model using the provided code (below).  Insert the relevant arrays into the corresponding tables in the database.\n",
    "\n",
    "**model_params**\n",
    "Values from the [`get_params`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.get_params) method.\n",
    "\n",
    "**model_coeffs**\n",
    "Coefficient and intercept values of the fitted model (see `coef_` and `intercept_` attributes in the documentation).\n",
    "\n",
    "**model_results**\n",
    "Train and validation accuracy obtained from the [`score`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.score) method.\n",
    "\n",
    "\n",
    "#### Remarks\n",
    "* Reference scikit-learn documentation to get more detail on the methods / attributes list above:  \n",
    "[https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "\n",
    "* Note that the *id* and *desc* are just identifier fields used to identify the results from a specific model iteration or scenario. For example for the baseline model you could set *id = 1* and *desc = \"Baseline model\"*.\n",
    "\n",
    "\n",
    "#### Suggestions\n",
    "You may want to create a function to save data to the database.  You will be able to re-use this function in subsequent sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p2.2'></a>\n",
    "## Problem 3 (10 points): \n",
    "Create a second model using only the features included in the list below (in `feature_cols`).  Insert the relevant arrays into the corresponding tables in the database.\n",
    "\n",
    "Remember to update the `id` and `desc` values for the second iteration.\n",
    "\n",
    "#### Suggestions\n",
    "* Name this second model `\"Reduced model\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['mean radius',\n",
    "                'texture error',\n",
    "                'worst radius',\n",
    "                'worst compactness',\n",
    "                'worst concavity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p2.3'></a>\n",
    "## Problem 4 (10 points): \n",
    "Create one last model using an **l1-penalty** ($L_{1}$) term and **all** the features. Insert the relevant arrays into the corresponding tables in the database.\n",
    "\n",
    "**Hint:** Refer to the `penalty` parameter of the `LogisticRegression` class.\n",
    "\n",
    "#### Suggestions\n",
    "Call this model `\"L1 penalty model\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part_3'></a>\n",
    "\n",
    "# Part 3:  Queries\n",
    "\n",
    "<a id='p3.1'></a>\n",
    "## Problem 5 (10 points): \n",
    "Query the database to identify the model with the highest validation score.\n",
    "* Print the id of the best model and the corresponding validation score.\n",
    "  ```bash\n",
    "  Best model id: \n",
    "  Best validation score:\n",
    "  ```\n",
    "* Print the feature names and corresponding coefficients of that model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p3.2'></a>\n",
    "## Problem 6 (10 points): \n",
    "\n",
    "Use the coefficients extracted in the previous question to reproduce the validation score (accuracy) of the best performing model (as stored in the database).\n",
    "\n",
    "**Hint:** You should be able to achieve this by overwriting the relevant variables in the Logistic regression object, i.e. there is no need write your own formula to generate individual predictions (you are welcome to do this if you want).\n",
    "\n",
    "#### Remarks\n",
    "The problem demos a simple scenario in which someone with access to your database can easily reproduce your results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
